{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "speaking-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "coated-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the collected datapoints json file\n",
    "df_yoga = pd.read_json('model/datapoints-ml5/yoga.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "knowing-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yoga_val = pd.read_json('model/datapoints-ml5/soumya-training.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "stable-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows',None,'display.max_columns',None):\n",
    "#     print(df_yoga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "seventh-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the individual angles of a pose\n",
    "# for i in range(14):\n",
    "#     print(df_yoga.at[0,'data'].get('xs').get(str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "instant-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the label\n",
    "# df_yoga.at[0,'data'].get('ys').get('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "thousand-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'a10', 'a11', 'a12', 'a13', 'pose']\n",
    "df_filtered = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "removed-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_test = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "covered-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_yoga.at[0,'data'].get('xs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "perceived-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting everything together for the training data\n",
    "# loop through the pandas yoga rows\n",
    "for i in range(len(df_yoga)):\n",
    "    temp_arr = []\n",
    "    # get the points first\n",
    "    for j in range(14):\n",
    "        temp_arr.append(df_yoga.at[i,'data'].get('xs').get(str(j)))\n",
    "    # get the label\n",
    "    temp_arr.append(df_yoga.at[i,'data'].get('ys').get('0'))\n",
    "    df_filtered.loc[i] = temp_arr\n",
    "# df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "promising-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting everything together for the testing data\n",
    "# loop through the pandas yoga rows\n",
    "for i in range(len(df_yoga_val)):\n",
    "    temp_arr = []\n",
    "    # get the points first\n",
    "    for j in range(14):\n",
    "        temp_arr.append(df_yoga_val.at[i,'data'].get('xs').get(str(j)))\n",
    "    # get the label\n",
    "    temp_arr.append(df_yoga_val.at[i,'data'].get('ys').get('0'))\n",
    "    df_filtered_test.loc[i] = temp_arr\n",
    "# df_filtered_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "defined-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to have numeric labels for tensorflow model\n",
    "labels_num = []\n",
    "pose_col = df_filtered['pose']\n",
    "for i in range(len(pose_col)):\n",
    "    if (pose_col[i]) == 'Mountain':\n",
    "        labels_num.append(0)\n",
    "    elif (pose_col[i]) == 'Tree':\n",
    "        labels_num.append(1)\n",
    "    elif (pose_col[i]) == 'Goddess':\n",
    "        labels_num.append(2)\n",
    "    elif (pose_col[i]) == 'Warrior 2':\n",
    "        labels_num.append(3)\n",
    "        \n",
    "labels_num = np.array(labels_num)\n",
    "# labels_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "sufficient-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing data\n",
    "labels_num_test = []\n",
    "pose_col = df_filtered_test['pose']\n",
    "for i in range(len(pose_col)):\n",
    "    if (pose_col[i]) == 'Mountain':\n",
    "        labels_num_test.append(0)\n",
    "    elif (pose_col[i]) == 'Tree':\n",
    "        labels_num_test.append(1)\n",
    "    elif (pose_col[i]) == 'Goddess':\n",
    "        labels_num_test.append(2)\n",
    "    elif (pose_col[i]) == 'Warrior 2':\n",
    "        labels_num_test.append(3)\n",
    "        \n",
    "labels_num_test = np.array(labels_num_test)\n",
    "# labels_num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ahead-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping last col with pose names\n",
    "df_filtered.drop(df_filtered.columns[-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "broad-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_test.drop(df_filtered_test.columns[-1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "exact-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "political-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train, features_test, labels_train, labels_test = train_test_split(df_filtered, labels_num, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "numeric-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "educated-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "adjusted-glance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale the training data\n",
    "scaler.fit(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "operational-reliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale the testing data\n",
    "scaler.fit(df_filtered_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "trying-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm the training data\n",
    "features_train = scaler.transform(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "changing-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm the validation data\n",
    "features_test = scaler.transform(df_filtered_test)\n",
    "# features_test = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ordinary-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "discrete-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "laughing-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "soviet-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "accessory-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(df_filtered.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "seventh-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_1 = Dense(15, activation='relu')(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "angry-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "willing-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(4, activation='softmax')(dense_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "documentary-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "digital-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "common-ontario",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2782 samples\n",
      "Epoch 1/100\n",
      "2782/2782 [==============================] - 0s 100us/sample - loss: 1.2606 - acc: 0.5712\n",
      "Epoch 2/100\n",
      "2782/2782 [==============================] - 0s 87us/sample - loss: 0.7485 - acc: 0.7189\n",
      "Epoch 3/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.4194 - acc: 0.8659\n",
      "Epoch 4/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.3195 - acc: 0.8961\n",
      "Epoch 5/100\n",
      "2782/2782 [==============================] - 0s 87us/sample - loss: 0.2763 - acc: 0.9058\n",
      "Epoch 6/100\n",
      "2782/2782 [==============================] - 0s 97us/sample - loss: 0.2506 - acc: 0.9148\n",
      "Epoch 7/100\n",
      "2782/2782 [==============================] - 0s 88us/sample - loss: 0.2322 - acc: 0.9198\n",
      "Epoch 8/100\n",
      "2782/2782 [==============================] - 0s 76us/sample - loss: 0.2152 - acc: 0.9263\n",
      "Epoch 9/100\n",
      "2782/2782 [==============================] - 0s 74us/sample - loss: 0.2031 - acc: 0.9310\n",
      "Epoch 10/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.1926 - acc: 0.9317\n",
      "Epoch 11/100\n",
      "2782/2782 [==============================] - 0s 77us/sample - loss: 0.1827 - acc: 0.9382\n",
      "Epoch 12/100\n",
      "2782/2782 [==============================] - 0s 74us/sample - loss: 0.1736 - acc: 0.9418\n",
      "Epoch 13/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.1643 - acc: 0.9450\n",
      "Epoch 14/100\n",
      "2782/2782 [==============================] - 0s 75us/sample - loss: 0.1573 - acc: 0.9493\n",
      "Epoch 15/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.1533 - acc: 0.9493\n",
      "Epoch 16/100\n",
      "2782/2782 [==============================] - 0s 87us/sample - loss: 0.1449 - acc: 0.9526\n",
      "Epoch 17/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.1408 - acc: 0.9526\n",
      "Epoch 18/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.1351 - acc: 0.9533\n",
      "Epoch 19/100\n",
      "2782/2782 [==============================] - 0s 86us/sample - loss: 0.1313 - acc: 0.9590\n",
      "Epoch 20/100\n",
      "2782/2782 [==============================] - 0s 87us/sample - loss: 0.1259 - acc: 0.9576\n",
      "Epoch 21/100\n",
      "2782/2782 [==============================] - 0s 90us/sample - loss: 0.1211 - acc: 0.9594\n",
      "Epoch 22/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.1142 - acc: 0.9615\n",
      "Epoch 23/100\n",
      "2782/2782 [==============================] - 0s 87us/sample - loss: 0.1131 - acc: 0.9630\n",
      "Epoch 24/100\n",
      "2782/2782 [==============================] - 0s 84us/sample - loss: 0.1105 - acc: 0.9615\n",
      "Epoch 25/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.1038 - acc: 0.9662\n",
      "Epoch 26/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.1009 - acc: 0.9709\n",
      "Epoch 27/100\n",
      "2782/2782 [==============================] - 0s 86us/sample - loss: 0.0989 - acc: 0.9694\n",
      "Epoch 28/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0961 - acc: 0.9680\n",
      "Epoch 29/100\n",
      "2782/2782 [==============================] - 0s 85us/sample - loss: 0.0911 - acc: 0.9691\n",
      "Epoch 30/100\n",
      "2782/2782 [==============================] - 0s 84us/sample - loss: 0.0924 - acc: 0.9716\n",
      "Epoch 31/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0888 - acc: 0.9716\n",
      "Epoch 32/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0836 - acc: 0.9745\n",
      "Epoch 33/100\n",
      "2782/2782 [==============================] - 0s 87us/sample - loss: 0.0838 - acc: 0.9727\n",
      "Epoch 34/100\n",
      "2782/2782 [==============================] - 0s 79us/sample - loss: 0.0805 - acc: 0.9741\n",
      "Epoch 35/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0794 - acc: 0.9752\n",
      "Epoch 36/100\n",
      "2782/2782 [==============================] - 0s 85us/sample - loss: 0.0763 - acc: 0.9752\n",
      "Epoch 37/100\n",
      "2782/2782 [==============================] - 0s 75us/sample - loss: 0.0775 - acc: 0.9723\n",
      "Epoch 38/100\n",
      "2782/2782 [==============================] - 0s 76us/sample - loss: 0.0773 - acc: 0.9752\n",
      "Epoch 39/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0727 - acc: 0.9777\n",
      "Epoch 40/100\n",
      "2782/2782 [==============================] - 0s 85us/sample - loss: 0.0742 - acc: 0.9777\n",
      "Epoch 41/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0702 - acc: 0.9759\n",
      "Epoch 42/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0696 - acc: 0.9756\n",
      "Epoch 43/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.0692 - acc: 0.9795\n",
      "Epoch 44/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.0695 - acc: 0.9770\n",
      "Epoch 45/100\n",
      "2782/2782 [==============================] - 0s 83us/sample - loss: 0.0708 - acc: 0.9752\n",
      "Epoch 46/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0658 - acc: 0.9781\n",
      "Epoch 47/100\n",
      "2782/2782 [==============================] - 0s 87us/sample - loss: 0.0652 - acc: 0.9795\n",
      "Epoch 48/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0647 - acc: 0.9781\n",
      "Epoch 49/100\n",
      "2782/2782 [==============================] - 0s 84us/sample - loss: 0.0655 - acc: 0.9774\n",
      "Epoch 50/100\n",
      "2782/2782 [==============================] - 0s 85us/sample - loss: 0.0631 - acc: 0.9788\n",
      "Epoch 51/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0625 - acc: 0.9806\n",
      "Epoch 52/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0627 - acc: 0.9792\n",
      "Epoch 53/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0656 - acc: 0.9792\n",
      "Epoch 54/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0603 - acc: 0.9802\n",
      "Epoch 55/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0601 - acc: 0.9781\n",
      "Epoch 56/100\n",
      "2782/2782 [==============================] - 0s 84us/sample - loss: 0.0595 - acc: 0.9809\n",
      "Epoch 57/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.0592 - acc: 0.9799\n",
      "Epoch 58/100\n",
      "2782/2782 [==============================] - 0s 86us/sample - loss: 0.0577 - acc: 0.9817\n",
      "Epoch 59/100\n",
      "2782/2782 [==============================] - 0s 83us/sample - loss: 0.0594 - acc: 0.9817\n",
      "Epoch 60/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.0553 - acc: 0.9831\n",
      "Epoch 61/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0577 - acc: 0.9813\n",
      "Epoch 62/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0559 - acc: 0.9824\n",
      "Epoch 63/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0556 - acc: 0.9795\n",
      "Epoch 64/100\n",
      "2782/2782 [==============================] - 0s 83us/sample - loss: 0.0566 - acc: 0.9827\n",
      "Epoch 65/100\n",
      "2782/2782 [==============================] - 0s 79us/sample - loss: 0.0548 - acc: 0.9835\n",
      "Epoch 66/100\n",
      "2782/2782 [==============================] - 0s 75us/sample - loss: 0.0530 - acc: 0.9820\n",
      "Epoch 67/100\n",
      "2782/2782 [==============================] - 0s 75us/sample - loss: 0.0563 - acc: 0.9795\n",
      "Epoch 68/100\n",
      "2782/2782 [==============================] - 0s 76us/sample - loss: 0.0558 - acc: 0.9817\n",
      "Epoch 69/100\n",
      "2782/2782 [==============================] - 0s 87us/sample - loss: 0.0522 - acc: 0.9813\n",
      "Epoch 70/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0530 - acc: 0.9831\n",
      "Epoch 71/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.0529 - acc: 0.9806\n",
      "Epoch 72/100\n",
      "2782/2782 [==============================] - 0s 83us/sample - loss: 0.0511 - acc: 0.9845\n",
      "Epoch 73/100\n",
      "2782/2782 [==============================] - 0s 84us/sample - loss: 0.0509 - acc: 0.9831\n",
      "Epoch 74/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.0520 - acc: 0.9820\n",
      "Epoch 75/100\n",
      "2782/2782 [==============================] - 0s 94us/sample - loss: 0.0510 - acc: 0.9831\n",
      "Epoch 76/100\n",
      "2782/2782 [==============================] - 0s 92us/sample - loss: 0.0492 - acc: 0.9856\n",
      "Epoch 77/100\n",
      "2782/2782 [==============================] - 0s 89us/sample - loss: 0.0499 - acc: 0.9845\n",
      "Epoch 78/100\n",
      "2782/2782 [==============================] - 0s 77us/sample - loss: 0.0498 - acc: 0.9835\n",
      "Epoch 79/100\n",
      "2782/2782 [==============================] - 0s 75us/sample - loss: 0.0510 - acc: 0.9842\n",
      "Epoch 80/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0510 - acc: 0.9820\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782/2782 [==============================] - 0s 75us/sample - loss: 0.0497 - acc: 0.9860\n",
      "Epoch 82/100\n",
      "2782/2782 [==============================] - 0s 78us/sample - loss: 0.0472 - acc: 0.9845\n",
      "Epoch 83/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0484 - acc: 0.9849\n",
      "Epoch 84/100\n",
      "2782/2782 [==============================] - 0s 76us/sample - loss: 0.0491 - acc: 0.9853\n",
      "Epoch 85/100\n",
      "2782/2782 [==============================] - 0s 89us/sample - loss: 0.0473 - acc: 0.9863\n",
      "Epoch 86/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0482 - acc: 0.9842\n",
      "Epoch 87/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.0481 - acc: 0.9838\n",
      "Epoch 88/100\n",
      "2782/2782 [==============================] - 0s 84us/sample - loss: 0.0512 - acc: 0.9842\n",
      "Epoch 89/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0475 - acc: 0.9863\n",
      "Epoch 90/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0495 - acc: 0.9838\n",
      "Epoch 91/100\n",
      "2782/2782 [==============================] - 0s 84us/sample - loss: 0.0490 - acc: 0.9838\n",
      "Epoch 92/100\n",
      "2782/2782 [==============================] - 0s 83us/sample - loss: 0.0499 - acc: 0.9838\n",
      "Epoch 93/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0465 - acc: 0.9835\n",
      "Epoch 94/100\n",
      "2782/2782 [==============================] - 0s 80us/sample - loss: 0.0503 - acc: 0.9827\n",
      "Epoch 95/100\n",
      "2782/2782 [==============================] - 0s 79us/sample - loss: 0.0451 - acc: 0.9871\n",
      "Epoch 96/100\n",
      "2782/2782 [==============================] - 0s 84us/sample - loss: 0.0469 - acc: 0.9835\n",
      "Epoch 97/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0466 - acc: 0.9842\n",
      "Epoch 98/100\n",
      "2782/2782 [==============================] - 0s 81us/sample - loss: 0.0494 - acc: 0.9849\n",
      "Epoch 99/100\n",
      "2782/2782 [==============================] - 0s 82us/sample - loss: 0.0454 - acc: 0.9860\n",
      "Epoch 100/100\n",
      "2782/2782 [==============================] - 0s 78us/sample - loss: 0.0479 - acc: 0.9849\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(features_train,labels_num,batch_size=8,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "contrary-browse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194/1194 [==============================] - 0s 31us/sample - loss: 0.4699 - acc: 0.8300\n"
     ]
    }
   ],
   "source": [
    "# get the validation data\n",
    "score = model.evaluate(features_test, labels_num_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "norwegian-diameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss score:  0.46993591165453996\n"
     ]
    }
   ],
   "source": [
    "print(\"loss score: \",  score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "indonesian-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.82998323\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-watson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-outline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
